{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0735459c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ray==0.8.7\n",
    "# !pip install ray[tune,rllib]\n",
    "# !pip install symfit\n",
    "# !pip install dm-tree\n",
    "# !pip install opencv-python\n",
    "# !pip install tensorboardX\n",
    "# !pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1447cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.spaces import Discrete\n",
    "\n",
    "from tensortrade.env.default.actions import TensorTradeActionScheme\n",
    "\n",
    "from tensortrade.env.generic import ActionScheme, TradingEnv\n",
    "from tensortrade.core import Clock\n",
    "from tensortrade.oms.instruments import ExchangePair\n",
    "from tensortrade.oms.wallets import Portfolio\n",
    "from tensortrade.oms.orders import (\n",
    "    Order,\n",
    "    proportion_order,\n",
    "    TradeSide,\n",
    "    TradeType\n",
    ")\n",
    "\n",
    "class BSH(TensorTradeActionScheme):\n",
    "\n",
    "    registered_name = \"bsh\"\n",
    "\n",
    "    def __init__(self, cash: 'Wallet', asset: 'Wallet'):\n",
    "        super().__init__()\n",
    "        self.cash = cash\n",
    "        self.asset = asset\n",
    "\n",
    "        self.listeners = []\n",
    "        self.action = 0\n",
    "\n",
    "    @property\n",
    "    def action_space(self):\n",
    "        return Discrete(2)\n",
    "\n",
    "    def attach(self, listener):\n",
    "        self.listeners += [listener]\n",
    "        return self\n",
    "\n",
    "    def get_orders(self, action: int, portfolio: 'Portfolio'):\n",
    "        order = None\n",
    "\n",
    "        if abs(action - self.action) > 0:\n",
    "            src = self.cash if self.action == 0 else self.asset\n",
    "            tgt = self.asset if self.action == 0 else self.cash\n",
    "            order = proportion_order(portfolio, src, tgt, 1.0)\n",
    "            self.action = action\n",
    "\n",
    "        for listener in self.listeners:\n",
    "            listener.on_action(action)\n",
    "\n",
    "        return [order]\n",
    "\n",
    "    def reset(self):\n",
    "        super().reset()\n",
    "        self.action = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309158d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensortrade.env.default.rewards import TensorTradeRewardScheme\n",
    "from tensortrade.feed.core import Stream, DataFeed\n",
    "\n",
    "class PBR(TensorTradeRewardScheme):\n",
    "\n",
    "    registered_name = \"pbr\"\n",
    "\n",
    "    def __init__(self, price: 'Stream'):\n",
    "        super().__init__()\n",
    "        self.position = -1\n",
    "\n",
    "        r = Stream.sensor(price, lambda p: p.value, dtype=\"float\").diff()\n",
    "        position = Stream.sensor(self, lambda rs: rs.position, dtype=\"float\")\n",
    "\n",
    "        reward = (r * position).fillna(0).rename(\"reward\")\n",
    "\n",
    "        self.feed = DataFeed([reward])\n",
    "        self.feed.compile()\n",
    "\n",
    "    def on_action(self, action: int):\n",
    "        self.position = -1 if action == 0 else 1\n",
    "\n",
    "    def get_reward(self, portfolio: 'Portfolio'):\n",
    "        return self.feed.next()[\"reward\"]\n",
    "\n",
    "    def reset(self):\n",
    "        self.position = -1\n",
    "        self.feed.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7739986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensortrade.env.generic import Renderer\n",
    "\n",
    "class PositionChangeChart(Renderer):\n",
    "\n",
    "    def __init__(self, color: str = \"orange\"):\n",
    "        self.color = \"orange\"\n",
    "\n",
    "    def render(self, env, **kwargs):\n",
    "        history = pd.DataFrame(env.observer.renderer_history)\n",
    "\n",
    "        actions = list(history.action)\n",
    "        p = list(history.price)\n",
    "\n",
    "        buy = {}\n",
    "        sell = {}\n",
    "\n",
    "        for i in range(len(actions) - 1):\n",
    "            a1 = actions[i]\n",
    "            a2 = actions[i + 1]\n",
    "\n",
    "            if a1 != a2:\n",
    "                if a1 == 0 and a2 == 1:\n",
    "                    buy[i] = p[i]\n",
    "                else:\n",
    "                    sell[i] = p[i]\n",
    "\n",
    "        buy = pd.Series(buy)\n",
    "        sell = pd.Series(sell)\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "        fig.suptitle(\"Performance\")\n",
    "\n",
    "        axs[0].plot(np.arange(len(p)), p, label=\"price\", color=self.color)\n",
    "        axs[0].scatter(buy.index, buy.values, marker=\"^\", color=\"green\")\n",
    "        axs[0].scatter(sell.index, sell.values, marker=\"^\", color=\"red\")\n",
    "        axs[0].set_title(\"Trading Chart\")\n",
    "        \n",
    "#         env.action_scheme.portfolio.performance.plot(ax=axs[1])\n",
    "        performance = pd.DataFrame.from_dict(env.action_scheme.portfolio.performance, orient='index')\n",
    "        performance.plot(ax=axs[1])\n",
    "        axs[1].set_title(\"Net Worth\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensortrade.oms.instruments import Instrument\n",
    "import pandas as pd\n",
    "\n",
    "USD = Instrument(\"USD\", 6, \"U.S. Dollar\")\n",
    "CAD = Instrument(\"CAD\", 6, \"Canadian Dollar\")\n",
    "\n",
    "df = pd.read_csv('data/USD_CAD_H4_2021-05-07.csv')\n",
    "\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28018402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "import tensortrade.env.default as default\n",
    "\n",
    "from tensortrade.feed.core import DataFeed, Stream\n",
    "from tensortrade.oms.exchanges import Exchange\n",
    "from tensortrade.oms.services.execution.simulated import execute_order\n",
    "from tensortrade.oms.wallets import Wallet, Portfolio\n",
    "\n",
    "def create_env(config):\n",
    "\n",
    "    x = df.index\n",
    "    y = df['close']\n",
    "    p = Stream.source(y, dtype=\"float\").rename(\"CAD-USD\")\n",
    "\n",
    "    USD = Instrument(\"USD\", 6, \"U.S. Dollar\")\n",
    "    CAD = Instrument(\"CAD\", 6, \"Canadian Dollar\")\n",
    "\n",
    "    oanda = Exchange(\"oanda\", service=execute_order)(\n",
    "                p\n",
    "            )\n",
    "\n",
    "    cash = Wallet(oanda, 500000 * CAD)\n",
    "    asset = Wallet(oanda, 1000 * USD)\n",
    "\n",
    "    portfolio = Portfolio(CAD, [\n",
    "        cash,\n",
    "        asset\n",
    "    ])\n",
    "\n",
    "    feed = DataFeed([\n",
    "        # p,\n",
    "        # p.rolling(window=10).mean().rename(\"fast\"),\n",
    "        # p.rolling(window=50).mean().rename(\"medium\"),\n",
    "        # p.rolling(window=100).mean().rename(\"slow\"),\n",
    "        # p.log().diff().fillna(0).rename(\"lr\")\n",
    "        Stream.source(df['close'], dtype=\"float\").rename(\"close\"),\n",
    "       Stream.source(df['open'], dtype=\"float\").rename(\"open\"),\n",
    "       Stream.source(df['high'], dtype=\"float\").rename(\"high\"),\n",
    "       Stream.source(df['low'], dtype=\"float\").rename(\"low\"),\n",
    "       Stream.source(df['volume'], dtype=\"float\").rename(\"volume\"),\n",
    "    ])\n",
    "\n",
    "    reward_scheme = PBR(price=p)\n",
    "\n",
    "    action_scheme = BSH(\n",
    "        cash=cash,\n",
    "        asset=asset\n",
    "    ).attach(reward_scheme)\n",
    "\n",
    "    renderer_feed = DataFeed([\n",
    "        Stream.source(y, dtype=\"float\").rename(\"price\"),\n",
    "        Stream.sensor(action_scheme, lambda s: s.action, dtype=\"float\").rename(\"action\")\n",
    "    ])\n",
    "\n",
    "    environment = default.create(\n",
    "        feed=feed,\n",
    "        portfolio=portfolio,\n",
    "        action_scheme=action_scheme,\n",
    "        reward_scheme=reward_scheme,\n",
    "        renderer_feed=renderer_feed,\n",
    "        renderer=PositionChangeChart(),\n",
    "        window_size=config[\"window_size\"],\n",
    "        max_allowed_loss=0.6\n",
    "    )\n",
    "    return environment\n",
    "\n",
    "register_env(\"TradingEnv\", create_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fe638e",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "    \"PPO\",\n",
    "    stop={\n",
    "      \"episode_reward_mean\": 10\n",
    "    },\n",
    "    config={\n",
    "        \"env\": \"TradingEnv\",\n",
    "        \"env_config\": {\n",
    "            \"window_size\": 25\n",
    "        },\n",
    "        \"log_level\": \"DEBUG\",\n",
    "        \"framework\": \"torch\",\n",
    "        \"ignore_worker_failures\": True,\n",
    "        \"num_workers\": 2,\n",
    "        \"num_gpus\": 0,\n",
    "        \"clip_rewards\": True,\n",
    "        \"lr\": 8e-6,\n",
    "        \"lr_schedule\": [\n",
    "            [0, 1e-1],\n",
    "            [int(1e2), 1e-2],\n",
    "            [int(1e3), 1e-3],\n",
    "            [int(1e4), 1e-4],\n",
    "            [int(1e5), 1e-5],\n",
    "            [int(1e6), 1e-6],\n",
    "            [int(1e7), 1e-7]\n",
    "        ],\n",
    "        \"gamma\": 0,\n",
    "        \"observation_filter\": \"MeanStdFilter\",\n",
    "        \"lambda\": 0.72,\n",
    "        \"vf_loss_coeff\": 0.5,\n",
    "        \"entropy_coeff\": 0.01\n",
    "    },\n",
    "    checkpoint_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefa38f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.rllib.agents.ppo as ppo\n",
    "\n",
    "# Get checkpoint\n",
    "checkpoints = analysis.get_trial_checkpoints_paths(\n",
    "    trial=analysis.get_best_trial(\"episode_reward_mean\"),\n",
    "    metric=\"episode_reward_mean\"\n",
    ")\n",
    "checkpoint_path = checkpoints[0][0]\n",
    "\n",
    "# Restore agent\n",
    "agent = ppo.PPOTrainer(\n",
    "    env=\"TradingEnv\",\n",
    "    config={\n",
    "        \"env_config\": {\n",
    "            \"window_size\": 25\n",
    "        },\n",
    "        \"framework\": \"torch\",\n",
    "        \"log_level\": \"DEBUG\",\n",
    "        \"ignore_worker_failures\": True,\n",
    "        \"num_workers\": 1,\n",
    "        \"num_gpus\": 0,\n",
    "        \"clip_rewards\": True,\n",
    "        \"lr\": 8e-6,\n",
    "        \"lr_schedule\": [\n",
    "            [0, 1e-1],\n",
    "            [int(1e2), 1e-2],\n",
    "            [int(1e3), 1e-3],\n",
    "            [int(1e4), 1e-4],\n",
    "            [int(1e5), 1e-5],\n",
    "            [int(1e6), 1e-6],\n",
    "            [int(1e7), 1e-7]\n",
    "        ],\n",
    "        \"gamma\": 0,\n",
    "        \"observation_filter\": \"MeanStdFilter\",\n",
    "        \"lambda\": 0.72,\n",
    "        \"vf_loss_coeff\": 0.5,\n",
    "        \"entropy_coeff\": 0.01\n",
    "    }\n",
    ")\n",
    "agent.restore(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa921a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the environment\n",
    "env = create_env({\n",
    "    \"window_size\": 25\n",
    "})\n",
    "\n",
    "# Run until episode ends\n",
    "episode_reward = 0\n",
    "done = False\n",
    "obs = env.reset()\n",
    "\n",
    "while not done:\n",
    "    action = agent.compute_action(obs)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    episode_reward += reward\n",
    "\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5d3178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from symfit import parameters, variables, sin, cos, Fit\n",
    "\n",
    "\n",
    "def fourier_series(x, f, n=0):\n",
    "    \"\"\"Creates a symbolic fourier series of order `n`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : `symfit.Variable`\n",
    "        The input variable for the function.\n",
    "    f : `symfit.Parameter`\n",
    "        Frequency of the fourier series\n",
    "    n : int\n",
    "        Order of the fourier series.\n",
    "    \"\"\"\n",
    "    # Make the parameter objects for all the terms\n",
    "    a0, *cos_a = parameters(','.join(['a{}'.format(i) for i in range(0, n + 1)]))\n",
    "    sin_b = parameters(','.join(['b{}'.format(i) for i in range(1, n + 1)]))\n",
    "\n",
    "    # Construct the series\n",
    "    series = a0 + sum(ai * cos(i * f * x) + bi * sin(i * f * x)\n",
    "                     for i, (ai, bi) in enumerate(zip(cos_a, sin_b), start=1))\n",
    "    return series\n",
    "\n",
    "\n",
    "def gbm(price: float,\n",
    "        mu: float,\n",
    "        sigma: float,\n",
    "        dt: float,\n",
    "        n: int) -> np.array:\n",
    "    \"\"\"Generates a geometric brownian motion path.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    price : float\n",
    "        The initial price of the series.\n",
    "    mu : float\n",
    "        The percentage drift.\n",
    "    sigma : float\n",
    "        The percentage volatility.\n",
    "    dt : float\n",
    "        The time step size.\n",
    "    n : int\n",
    "        The number of steps to be generated in the path.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `np.array`\n",
    "        The generated path.\n",
    "    \"\"\"\n",
    "    y = np.exp((mu - sigma ** 2 / 2) * dt + sigma * np.random.normal(0, np.sqrt(dt), size=n).T)\n",
    "    y = price * y.cumprod(axis=0)\n",
    "    return y\n",
    "\n",
    "\n",
    "def fourier_gbm(price, mu, sigma, dt, n, order):\n",
    "\n",
    "    x, y = variables('x, y')\n",
    "    w, = parameters('w')\n",
    "    model_dict = {y: fourier_series(x, f=w, n=order)}\n",
    "\n",
    "    # Make step function data\n",
    "    xdata = np.arange(-np.pi, np.pi, 2*np.pi / n)\n",
    "    ydata = np.log(gbm(price, mu, sigma, dt, n))\n",
    "\n",
    "    # Define a Fit object for this model and data\n",
    "    fit = Fit(model_dict, x=xdata, y=ydata)\n",
    "    fit_result = fit.execute()\n",
    "\n",
    "    return np.exp(fit.model(x=xdata, **fit_result.params).y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d47382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eval_env(config):\n",
    "    y = config[\"y\"]\n",
    "\n",
    "    x = np.arange(0, 2*np.pi, 2*np.pi / 1000)\n",
    "    p = Stream.source(y, dtype=\"float\").rename(\"USD-TTC\")\n",
    "\n",
    "    bitfinex = Exchange(\"bitfinex\", service=execute_order)(\n",
    "        p\n",
    "    )\n",
    "\n",
    "    cash = Wallet(bitfinex, 100000 * USD)\n",
    "    asset = Wallet(bitfinex, 0 * TTC)\n",
    "\n",
    "    portfolio = Portfolio(USD, [\n",
    "        cash,\n",
    "        asset\n",
    "    ])\n",
    "\n",
    "    feed = DataFeed([\n",
    "        p,\n",
    "        p.rolling(window=10).mean().rename(\"fast\"),\n",
    "        p.rolling(window=50).mean().rename(\"medium\"),\n",
    "        p.rolling(window=100).mean().rename(\"slow\"),\n",
    "        p.log().diff().fillna(0).rename(\"lr\")\n",
    "    ])\n",
    "\n",
    "    reward_scheme = PBR(price=p)\n",
    "\n",
    "    action_scheme = BSH(\n",
    "        cash=cash,\n",
    "        asset=asset\n",
    "    ).attach(reward_scheme)\n",
    "\n",
    "    renderer_feed = DataFeed([\n",
    "        Stream.source(y, dtype=\"float\").rename(\"price\"),\n",
    "        Stream.sensor(action_scheme, lambda s: s.action, dtype=\"float\").rename(\"action\")\n",
    "    ])\n",
    "\n",
    "    environment = default.create(\n",
    "        feed=feed,\n",
    "        portfolio=portfolio,\n",
    "        action_scheme=action_scheme,\n",
    "        reward_scheme=reward_scheme,\n",
    "        renderer_feed=renderer_feed,\n",
    "        renderer=PositionChangeChart(),\n",
    "        window_size=config[\"window_size\"],\n",
    "        max_allowed_loss=0.2\n",
    "    )\n",
    "    return environment\n",
    "\n",
    "for _ in range(6):\n",
    "    # Instantiate the environment\n",
    "    env = create_eval_env({\n",
    "        \"window_size\": 25,\n",
    "        \"y\": fourier_gbm(price=100, mu=0.1, sigma=0.5, dt=0.01, n=1000, order=5)\n",
    "    })\n",
    "\n",
    "\n",
    "    # Run until episode ends\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "\n",
    "    while not done:\n",
    "        action = agent.compute_action(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        episode_reward += reward\n",
    "\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensortrade.oms.instruments import Instrument\n",
    "\n",
    "USD = Instrument(\"USD\", 6, \"U.S. Dollar\")\n",
    "CAD = Instrument(\"CAD\", 6, \"Canadian Dollar\")\n",
    "\n",
    "def create_eval_env(config):\n",
    "    df = pd.read_csv('data/USD_CAD_H1_2021-05-03.csv')\n",
    "    y = df['close']\n",
    "    p = Stream.source(y, dtype=\"float\").rename(\"USD-CAD\")\n",
    "\n",
    "    oanda = Exchange(\"oanda\", service=execute_order)(\n",
    "        p\n",
    "    )\n",
    "\n",
    "    cash = Wallet(oanda, 10000 * USD)\n",
    "    asset = Wallet(oanda, 10000 * CAD)\n",
    "\n",
    "    portfolio = Portfolio(USD, [\n",
    "        cash,\n",
    "        asset\n",
    "    ])\n",
    "\n",
    "    feed = DataFeed([\n",
    "        p,\n",
    "        p.rolling(window=10).mean().rename(\"fast\"),\n",
    "        p.rolling(window=50).mean().rename(\"medium\"),\n",
    "        p.rolling(window=100).mean().rename(\"slow\"),\n",
    "        p.log().diff().fillna(0).rename(\"lr\")\n",
    "    ])\n",
    "\n",
    "    reward_scheme = PBR(price=p)\n",
    "\n",
    "    action_scheme = BSH(\n",
    "        cash=cash,\n",
    "        asset=asset\n",
    "    ).attach(reward_scheme)\n",
    "\n",
    "    renderer_feed = DataFeed([\n",
    "        Stream.source(y, dtype=\"float\").rename(\"price\"),\n",
    "        Stream.sensor(action_scheme, lambda s: s.action, dtype=\"float\").rename(\"action\")\n",
    "    ])\n",
    "\n",
    "    environment = default.create(\n",
    "        feed=feed,\n",
    "        portfolio=portfolio,\n",
    "        action_scheme=action_scheme,\n",
    "        reward_scheme=reward_scheme,\n",
    "        renderer_feed=renderer_feed,\n",
    "        renderer=PositionChangeChart(),\n",
    "        window_size=config[\"window_size\"],\n",
    "        max_allowed_loss=0.2\n",
    "    )\n",
    "    return environment\n",
    "\n",
    "env = create_eval_env({\n",
    "    \"window_size\": 25\n",
    "})\n",
    "\n",
    "\n",
    "# Run until episode ends\n",
    "episode_reward = 0\n",
    "done = False\n",
    "obs = env.reset()\n",
    "\n",
    "while not done:\n",
    "    action = agent.compute_action(obs)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    print(info)\n",
    "    episode_reward += reward\n",
    "\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasgui import show\n",
    "\n",
    "performance = pd.DataFrame.from_dict(env.action_scheme.portfolio.performance, orient='index')\n",
    "\n",
    "gui = show(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gui = show(env.action_scheme.portfolio.ledger.as_frame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd01c4c0bf6beae42fd240ca5a341f6bd890b27028c2190f4d96dbd3777b38ff428",
   "display_name": "Python 3.8.8 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}